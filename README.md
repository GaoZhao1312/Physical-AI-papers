### Baseline
- **Learning Transferable Visual Models From Natural Language Supervision** (2021). [[pdf]](https://arxiv.org/abs/2103.00020)
- **BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation** (2022). [[pdf]](https://arxiv.org/abs/2201.12086)
- **BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models** (2023). [[pdf]](https://arxiv.org/abs/2301.12597)
- **Visual Instruction Tuning** (2023). [[pdf]](https://arxiv.org/abs/2304.08485)
- **Improved Baselines with Visual Instruction Tuning** (2024). [[pdf]](https://arxiv.org/abs/2310.03744)
- **LLaVA-OneVision: Easy Visual Task Transfer** (2024). [[pdf]](https://arxiv.org/abs/2408.03326)
- **LoRA: Low-Rank Adaptation of Large Language Models** (2021). [[pdf]](https://arxiv.org/abs/2106.09685)
- **Proximal Policy Optimization Algorithms** (2017). [[pdf]](https://arxiv.org/abs/1707.06347)
- **Vision as LoRA** (2025). [[pdf]](https://arxiv.org/abs/2503.20680)
- **Proximal Policy Optimization Algorithms** (2017). [[pdf]](https://arxiv.org/abs/1707.06347)
- **Mamba: Linear-Time Sequence Modeling with Selective State Spaces** (2023). [[pdf]](https://arxiv.org/abs/2312.00752)
- **Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model** (2024). [[pdf]](https://arxiv.org/abs/2401.09417)
- **End-to-End Multi-Modal Diffusion Mamba** (2025). [[pdf]](https://arxiv.org/pdf/2510.13253)
  
### Survey
- **A Survey of Camouflaged Object Detection and Beyond** (2024). [[pdf]](https://arxiv.org/pdf/2408.14562)
- **Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation** (2025). [[pdf]](https://arxiv.org/html/2502.08826v2)
- **Multimodal large language models and physics visual tasks: comparative analysis of performance and costs** (2025). [[pdf]](https://arxiv.org/pdf/2506.19662v1)
- **A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models** (2024). [[pdf]](https://arxiv.org/abs/2307.12980)
- **Generative Physical AI in Vision: A Survey** (2025). [[pdf]](https://arxiv.org/abs/2501.10928)
- **Does Physics Knowledge Emerge in Frontier Models?** (2025). [[pdf]](https://arxiv.org/abs/2510.06251)

### Understanding/Reasoning/Generation
- **Physics Context Builders: A Modular Framework for Physical Reasoning in Vision-Language Models** (2025). [[pdf]](https://arxiv.org/abs/2412.08619)
- **GigaVideo-1: Advancing Video Generation via Automatic Feedback with 4 GPU-Hours Fine-Tuning** (2025). [[pdf]](https://arxiv.org/pdf/2506.10639)
- **PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models** (2025). [[pdf]](https://arxiv.org/abs/2506.17667)
- **ABench-Physics: Benchmarking Physical Reasoning in LLMs via High-Difficulty and Dynamic Physics Problems** (2025). [[pdf]](https://arxiv.org/abs/2507.04766)
- **Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning** (2025). [[pdf]](https://arxiv.org/abs/2503.15558)
- **Deep Correlated Prompting for Visual Recognition with Missing Modalities** (2024). [[pdf]](https://arxiv.org/abs/2410.06558)
- **Inducing Causal World Models in LLMs for Zero-Shot Physical Reasoning** (2025). [[pdf]](https://arxiv.org/abs/2507.19855)
- **Multimodal Chain-of-Thought Reasoning in Language Models** (2024). [[pdf]](https://arxiv.org/abs/2302.00923)
- **PhyX: Does Your Model Have the "Wits" for Physical Reasoning?** (2025). [[pdf]](https://arxiv.org/abs/2505.15929)
- **From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models** (2025). [[pdf]](https://arxiv.org/abs/2508.10770)
- **Prompt-CAM: Making Vision Transformers Interpretable for Fine-Grained Analysis** (2025). [[pdf]](https://arxiv.org/abs/2501.09333)
- **Seeing is Not Reasoning: MVPBench for Graph-based Evaluation of Multi-path Visual Physical CoT** (2025). [[pdf]](https://arxiv.org/abs/2505.24182)
- **Sim Anything: Automated 3D Physical Simulation of Open-world Scene with Gaussian Splatting** (2024). [[pdf]](https://arxiv.org/html/2411.12789v1)
- **Synthetic Video Enhances Physical Fidelity in Video Synthesis** (2025). [[pdf]](https://arxiv.org/abs/2503.20822)
- **GRIT: Teaching MLLMs to Think with Images** (2025). [[pdf]](https://arxiv.org/abs/2505.15879)
- **VLIPP: Towards Physically Plausible Video Generation with Vision and Language Informed Physical Prior** (2025). [[pdf]](https://arxiv.org/abs/2503.23368)
- **Visualized Text-to-Image Retrieval** (2025). [[pdf]](https://arxiv.org/abs/2505.20291)
- **Universal Multimodal Representation for Language Understanding** (2023). [[pdf]](https://arxiv.org/abs/2301.03344)
- **Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video** (2024). [[pdf]](https://arxiv.org/abs/2404.09833)
- **Reconstruction Alignment Improves Unified Multimodal Models** (2025). [[pdf]](https://arxiv.org/pdf/2509.07295)
- **Reconstructive Visual Instruction Tuning** (2025). [[pdf]](https://arxiv.org/pdf/2410.09575)
- **QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation** (2025). [[pdf]](https://arxiv.org/abs/2507.13266)
- **FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving** (2025). [[pdf]](https://arxiv.org/abs/2505.17685)
- **Inferring Dynamic Physical Properties from Video Foundation Models** (2025). [[pdf]](https://arxiv.org/abs/2510.02311)
- **Introducing Visual Perception Token into Multimodal Large Language Model** (2025). [[pdf]](https://arxiv.org/abs/2502.17425)
- **Physics-Driven Spatiotemporal Modeling for AI-Generated Video Detection** (2025). [[pdf]](https://arxiv.org/abs/2510.08073)
- **TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility** (2025). [[pdf]](https://arxiv.org/abs/2510.07550)
- **Enhancing Physical Plausibility in Video Generation by Reasoning the Implausibility** (2025). [[pdf]](https://arxiv.org/pdf/2509.24702)
- **Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation** (2025). [[pdf]](https://arxiv.org/abs/2508.10858)
- **Visual Embodied Brain: Let Multimodal Large Language Models See, Think, and Control in Spaces** (2025). [[pdf]](https://arxiv.org/abs/2506.00123)
- **PhysVLM-AVR: Active Visual Reasoning for Multimodal Large Language Models in Physical Environments** (2025). [[pdf]](https://arxiv.org/html/2510.21111v1)
